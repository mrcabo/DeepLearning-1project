Using TensorFlow backend.
Training with:
Network model name: vgg16
Batch size: 64
Epochs: 100
Optimizer: Adam
Loss: categorical_crossentropy
Dropout: False
Data augmentation: True
Pre-trained: False
Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz
170500096/170498071 [==============================] - 16s 0us/step
x_train shape: (50000, 32, 32, 3)
50000 train samples
10000 test samples
y_train shape: (50000, 1)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
Learning rate:  1e-05
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_1 (InputLayer)         (None, 32, 32, 3)         0         
_________________________________________________________________
block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      
_________________________________________________________________
block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     
_________________________________________________________________
block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         
_________________________________________________________________
block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     
_________________________________________________________________
block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    
_________________________________________________________________
block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         
_________________________________________________________________
block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    
_________________________________________________________________
block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    
_________________________________________________________________
block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         
_________________________________________________________________
block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   
_________________________________________________________________
block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   
_________________________________________________________________
block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         
_________________________________________________________________
block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   
_________________________________________________________________
block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         
_________________________________________________________________
global_average_pooling2d_1 ( (None, 512)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 1024)              525312    
_________________________________________________________________
dense_2 (Dense)              (None, 10)                10250     
=================================================================
Total params: 15,250,250
Trainable params: 15,250,250
Non-trainable params: 0
_________________________________________________________________
If not empty, the code is using GPU:
['/job:localhost/replica:0/task:0/device:GPU:0']
Using real-time data augmentation.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
Epoch 1/100
Learning rate:  1e-05
 - 46s - loss: 2.0285 - acc: 0.2287 - val_loss: 1.8177 - val_acc: 0.3222
Epoch 2/100
Learning rate:  1e-05
 - 40s - loss: 1.7708 - acc: 0.3302 - val_loss: 1.6460 - val_acc: 0.3705
Epoch 3/100
Learning rate:  1e-05
 - 40s - loss: 1.6739 - acc: 0.3656 - val_loss: 1.5825 - val_acc: 0.3947
Epoch 4/100
Learning rate:  1e-05
 - 40s - loss: 1.6115 - acc: 0.3914 - val_loss: 1.5496 - val_acc: 0.4099
Epoch 5/100
Learning rate:  1e-05
 - 40s - loss: 1.5580 - acc: 0.4139 - val_loss: 1.5150 - val_acc: 0.4283
Epoch 6/100
Learning rate:  1e-05
 - 40s - loss: 1.5145 - acc: 0.4338 - val_loss: 1.4481 - val_acc: 0.4504
Epoch 7/100
Learning rate:  1e-05
 - 40s - loss: 1.4734 - acc: 0.4526 - val_loss: 1.4150 - val_acc: 0.4705
Epoch 8/100
Learning rate:  1e-05
 - 40s - loss: 1.4364 - acc: 0.4694 - val_loss: 1.4282 - val_acc: 0.4767
Epoch 9/100
Learning rate:  1e-05
 - 40s - loss: 1.4041 - acc: 0.4806 - val_loss: 1.3715 - val_acc: 0.4916
Epoch 10/100
Learning rate:  1e-05
 - 40s - loss: 1.3782 - acc: 0.4906 - val_loss: 1.4691 - val_acc: 0.4807
Epoch 11/100
Learning rate:  1e-05
 - 40s - loss: 1.3500 - acc: 0.5015 - val_loss: 1.2732 - val_acc: 0.5366
Epoch 12/100
Learning rate:  1e-05
 - 40s - loss: 1.3260 - acc: 0.5095 - val_loss: 1.3105 - val_acc: 0.5213
Epoch 13/100
Learning rate:  1e-05
 - 40s - loss: 1.2995 - acc: 0.5235 - val_loss: 1.2391 - val_acc: 0.5476
Epoch 14/100
Learning rate:  1e-05
 - 40s - loss: 1.2760 - acc: 0.5321 - val_loss: 1.2419 - val_acc: 0.5424
Epoch 15/100
Learning rate:  1e-05
 - 40s - loss: 1.2559 - acc: 0.5411 - val_loss: 1.1958 - val_acc: 0.5599
Epoch 16/100
Learning rate:  1e-05
 - 40s - loss: 1.2273 - acc: 0.5501 - val_loss: 1.2427 - val_acc: 0.5482
Epoch 17/100
Learning rate:  1e-05
 - 40s - loss: 1.2145 - acc: 0.5550 - val_loss: 1.2013 - val_acc: 0.5656
Epoch 18/100
Learning rate:  1e-05
 - 40s - loss: 1.1918 - acc: 0.5659 - val_loss: 1.2181 - val_acc: 0.5591
Epoch 19/100
Learning rate:  1e-05
 - 40s - loss: 1.1724 - acc: 0.5726 - val_loss: 1.1606 - val_acc: 0.5813
Epoch 20/100
Learning rate:  1e-05
 - 40s - loss: 1.1508 - acc: 0.5806 - val_loss: 1.1572 - val_acc: 0.5841
Epoch 21/100
Learning rate:  1e-05
 - 40s - loss: 1.1355 - acc: 0.5872 - val_loss: 1.1061 - val_acc: 0.5972
Epoch 22/100
Learning rate:  1e-05
 - 40s - loss: 1.1211 - acc: 0.5944 - val_loss: 1.1068 - val_acc: 0.5988
Epoch 23/100
Learning rate:  1e-05
 - 40s - loss: 1.1028 - acc: 0.6021 - val_loss: 1.1023 - val_acc: 0.6015
Epoch 24/100
Learning rate:  1e-05
 - 40s - loss: 1.0919 - acc: 0.6009 - val_loss: 1.0718 - val_acc: 0.6077
Epoch 25/100
Learning rate:  1e-05
 - 40s - loss: 1.0666 - acc: 0.6109 - val_loss: 1.1233 - val_acc: 0.6013
Epoch 26/100
Learning rate:  1e-05
 - 40s - loss: 1.0557 - acc: 0.6160 - val_loss: 1.0321 - val_acc: 0.6236
Epoch 27/100
Learning rate:  1e-05
 - 40s - loss: 1.0404 - acc: 0.6197 - val_loss: 1.0704 - val_acc: 0.6147
Epoch 28/100
Learning rate:  1e-05
 - 40s - loss: 1.0240 - acc: 0.6295 - val_loss: 1.0321 - val_acc: 0.6321
Epoch 29/100
Learning rate:  1e-05
 - 40s - loss: 1.0097 - acc: 0.6331 - val_loss: 1.0490 - val_acc: 0.6253
Epoch 30/100
Learning rate:  1e-05
 - 40s - loss: 0.9981 - acc: 0.6372 - val_loss: 1.0416 - val_acc: 0.6235
Epoch 31/100
Learning rate:  1e-05
 - 40s - loss: 0.9852 - acc: 0.6435 - val_loss: 0.9975 - val_acc: 0.6411
Epoch 32/100
Learning rate:  1e-05
 - 40s - loss: 0.9720 - acc: 0.6498 - val_loss: 0.9589 - val_acc: 0.6561
Epoch 33/100
Learning rate:  1e-05
 - 40s - loss: 0.9605 - acc: 0.6521 - val_loss: 0.9870 - val_acc: 0.6515
Epoch 34/100
Learning rate:  1e-05
 - 40s - loss: 0.9414 - acc: 0.6600 - val_loss: 0.9324 - val_acc: 0.6700
Epoch 35/100
Learning rate:  1e-05
 - 40s - loss: 0.9315 - acc: 0.6639 - val_loss: 0.9802 - val_acc: 0.6497
Epoch 36/100
Learning rate:  1e-05
 - 40s - loss: 0.9189 - acc: 0.6683 - val_loss: 0.9409 - val_acc: 0.6642
Epoch 37/100
Learning rate:  1e-05
 - 40s - loss: 0.9101 - acc: 0.6691 - val_loss: 0.9396 - val_acc: 0.6657
Epoch 38/100
Learning rate:  1e-05
 - 40s - loss: 0.8978 - acc: 0.6767 - val_loss: 0.9327 - val_acc: 0.6704
Epoch 39/100
Learning rate:  1e-05
 - 40s - loss: 0.8820 - acc: 0.6828 - val_loss: 0.9416 - val_acc: 0.6664
Epoch 40/100
Learning rate:  1e-05
 - 40s - loss: 0.8716 - acc: 0.6855 - val_loss: 0.8725 - val_acc: 0.6884
Epoch 41/100
Learning rate:  1e-05
 - 40s - loss: 0.8583 - acc: 0.6893 - val_loss: 0.9170 - val_acc: 0.6746
Epoch 42/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.8082 - acc: 0.7085 - val_loss: 0.8651 - val_acc: 0.6946
Epoch 43/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.8002 - acc: 0.7117 - val_loss: 0.8627 - val_acc: 0.6955
Epoch 44/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7999 - acc: 0.7088 - val_loss: 0.8405 - val_acc: 0.7003
Epoch 45/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7988 - acc: 0.7138 - val_loss: 0.8590 - val_acc: 0.6955
Epoch 46/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7933 - acc: 0.7153 - val_loss: 0.8595 - val_acc: 0.6957
Epoch 47/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7952 - acc: 0.7144 - val_loss: 0.8530 - val_acc: 0.6977
Epoch 48/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7893 - acc: 0.7149 - val_loss: 0.8505 - val_acc: 0.6983
Epoch 49/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7881 - acc: 0.7165 - val_loss: 0.8327 - val_acc: 0.7037
Epoch 50/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7868 - acc: 0.7191 - val_loss: 0.8548 - val_acc: 0.6985
Epoch 51/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7821 - acc: 0.7179 - val_loss: 0.8381 - val_acc: 0.7019
Epoch 52/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7844 - acc: 0.7175 - val_loss: 0.8479 - val_acc: 0.7011
Epoch 53/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7831 - acc: 0.7188 - val_loss: 0.8480 - val_acc: 0.6982
Epoch 54/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7815 - acc: 0.7181 - val_loss: 0.8399 - val_acc: 0.7013
Epoch 55/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7771 - acc: 0.7206 - val_loss: 0.8609 - val_acc: 0.6934
Epoch 56/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7762 - acc: 0.7219 - val_loss: 0.8249 - val_acc: 0.7059
Epoch 57/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7761 - acc: 0.7230 - val_loss: 0.8199 - val_acc: 0.7093
Epoch 58/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7714 - acc: 0.7223 - val_loss: 0.8426 - val_acc: 0.7014
Epoch 59/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7692 - acc: 0.7243 - val_loss: 0.8225 - val_acc: 0.7066
Epoch 60/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7678 - acc: 0.7243 - val_loss: 0.8413 - val_acc: 0.7022
Epoch 61/100
Learning rate:  1.0000000000000002e-06
 - 40s - loss: 0.7686 - acc: 0.7238 - val_loss: 0.8407 - val_acc: 0.7033
Epoch 62/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7575 - acc: 0.7280 - val_loss: 0.8275 - val_acc: 0.7062
Epoch 63/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7587 - acc: 0.7297 - val_loss: 0.8294 - val_acc: 0.7054
Epoch 64/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7606 - acc: 0.7259 - val_loss: 0.8320 - val_acc: 0.7041
Epoch 65/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7572 - acc: 0.7296 - val_loss: 0.8301 - val_acc: 0.7044
Epoch 66/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7607 - acc: 0.7264 - val_loss: 0.8287 - val_acc: 0.7056
Epoch 67/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7579 - acc: 0.7263 - val_loss: 0.8261 - val_acc: 0.7056
Epoch 68/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7622 - acc: 0.7264 - val_loss: 0.8304 - val_acc: 0.7048
Epoch 69/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7593 - acc: 0.7277 - val_loss: 0.8278 - val_acc: 0.7057
Epoch 70/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7595 - acc: 0.7261 - val_loss: 0.8258 - val_acc: 0.7062
Epoch 71/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7574 - acc: 0.7299 - val_loss: 0.8289 - val_acc: 0.7048
Epoch 72/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7576 - acc: 0.7276 - val_loss: 0.8279 - val_acc: 0.7057
Epoch 73/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7589 - acc: 0.7268 - val_loss: 0.8329 - val_acc: 0.7036
Epoch 74/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7608 - acc: 0.7273 - val_loss: 0.8291 - val_acc: 0.7049
Epoch 75/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7575 - acc: 0.7280 - val_loss: 0.8190 - val_acc: 0.7092
Epoch 76/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7531 - acc: 0.7309 - val_loss: 0.8268 - val_acc: 0.7057
Epoch 77/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7547 - acc: 0.7303 - val_loss: 0.8263 - val_acc: 0.7064
Epoch 78/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7555 - acc: 0.7292 - val_loss: 0.8272 - val_acc: 0.7062
Epoch 79/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7572 - acc: 0.7275 - val_loss: 0.8216 - val_acc: 0.7082
Epoch 80/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7555 - acc: 0.7286 - val_loss: 0.8260 - val_acc: 0.7065
Epoch 81/100
Learning rate:  1.0000000000000001e-07
 - 40s - loss: 0.7574 - acc: 0.7290 - val_loss: 0.8252 - val_acc: 0.7055
Epoch 82/100
Learning rate:  1e-08
 - 40s - loss: 0.7548 - acc: 0.7300 - val_loss: 0.8266 - val_acc: 0.7051
Epoch 83/100
Learning rate:  1e-08
 - 40s - loss: 0.7565 - acc: 0.7282 - val_loss: 0.8267 - val_acc: 0.7053
Epoch 84/100
Learning rate:  1e-08
 - 40s - loss: 0.7531 - acc: 0.7294 - val_loss: 0.8271 - val_acc: 0.7056
Epoch 85/100
Learning rate:  1e-08
 - 40s - loss: 0.7543 - acc: 0.7296 - val_loss: 0.8274 - val_acc: 0.7051
Epoch 86/100
Learning rate:  1e-08
 - 40s - loss: 0.7541 - acc: 0.7286 - val_loss: 0.8275 - val_acc: 0.7057
Epoch 87/100
Learning rate:  1e-08
 - 40s - loss: 0.7581 - acc: 0.7271 - val_loss: 0.8271 - val_acc: 0.7050
Epoch 88/100
Learning rate:  1e-08
 - 40s - loss: 0.7571 - acc: 0.7274 - val_loss: 0.8274 - val_acc: 0.7057
Epoch 89/100
Learning rate:  1e-08
 - 40s - loss: 0.7569 - acc: 0.7287 - val_loss: 0.8275 - val_acc: 0.7054
Epoch 90/100
Learning rate:  1e-08
 - 40s - loss: 0.7563 - acc: 0.7287 - val_loss: 0.8273 - val_acc: 0.7052
Epoch 91/100
Learning rate:  1e-08
 - 40s - loss: 0.7576 - acc: 0.7296 - val_loss: 0.8270 - val_acc: 0.7060
Epoch 92/100
Learning rate:  5e-09
 - 40s - loss: 0.7558 - acc: 0.7298 - val_loss: 0.8277 - val_acc: 0.7051
Epoch 93/100
Learning rate:  5e-09
 - 40s - loss: 0.7540 - acc: 0.7304 - val_loss: 0.8273 - val_acc: 0.7052
Epoch 94/100
Learning rate:  5e-09
 - 40s - loss: 0.7546 - acc: 0.7289 - val_loss: 0.8271 - val_acc: 0.7057
Epoch 95/100
Learning rate:  5e-09
 - 40s - loss: 0.7556 - acc: 0.7304 - val_loss: 0.8272 - val_acc: 0.7053
Epoch 96/100
Learning rate:  5e-09
 - 40s - loss: 0.7578 - acc: 0.7280 - val_loss: 0.8274 - val_acc: 0.7051
Epoch 97/100
Learning rate:  5e-09
 - 40s - loss: 0.7569 - acc: 0.7295 - val_loss: 0.8272 - val_acc: 0.7053
Epoch 98/100
Learning rate:  5e-09
 - 40s - loss: 0.7563 - acc: 0.7296 - val_loss: 0.8274 - val_acc: 0.7046
Epoch 99/100
Learning rate:  5e-09
 - 40s - loss: 0.7516 - acc: 0.7317 - val_loss: 0.8270 - val_acc: 0.7051
Epoch 100/100
Learning rate:  5e-09
 - 40s - loss: 0.7557 - acc: 0.7303 - val_loss: 0.8274 - val_acc: 0.7054


Test loss: 0.8273683562278747
Test accuracy: 0.7054
<Figure size 432x288 with 0 Axes>

